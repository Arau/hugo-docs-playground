<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> – Documentation</title>
    <link>/docs/</link>
    <description>Recent content in Documentation on </description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Installing on OpenShift 4.2</title>
      <link>/docs/platforms/openshift/install/4.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/4.2/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/openshift-install-4.x.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes {{ page.k8s-version }}</title>
      <link>/docs/platforms/kubernetes/install/1.17/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/install/1.17/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing on OpenShift 4.1</title>
      <link>/docs/platforms/openshift/install/4.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/4.1/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/openshift-install-4.x.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes {{ page.k8s-version }}</title>
      <link>/docs/platforms/kubernetes/install/1.16/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/install/1.16/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing on OpenShift 3.11</title>
      <link>/docs/platforms/openshift/install/3.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/3.11/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/openshift-install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes {{ page.k8s-version }}</title>
      <link>/docs/platforms/kubernetes/install/1.15/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/install/1.15/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing on OpenShift 3.10</title>
      <link>/docs/platforms/openshift/install/3.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/3.10/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/openshift-install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes {{ page.k8s-version }}</title>
      <link>/docs/platforms/kubernetes/install/1.14/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/install/1.14/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing on OpenShift 3.9</title>
      <link>/docs/platforms/openshift/install/3.9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/3.9/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/openshift-install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes {{ page.k8s-version }}</title>
      <link>/docs/platforms/kubernetes/install/1.13/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/install/1.13/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing on OpenShift 3.8</title>
      <link>/docs/platforms/openshift/install/3.8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/3.8/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS requires &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation&#34;&gt;mount
propagation&lt;/a&gt;
in order to present devices as volumes to containers. In OpenShift 3.8 this feature is in alpha, so needs to be explicity enabled.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set &lt;code&gt;--feature-gates MountPropagation=true&lt;/code&gt; in the kube-apiserver and
kube-controller-manager deployments, usually found in the master nodes under
&lt;code&gt;/etc/kubernetes/manifests&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;KUBELET_EXTRA_ARGS=--feature-gates=MountPropagation=true&lt;/code&gt; in the kubelet
service config. For systemd, this usually is located in &lt;code&gt;/etc/systemd/system/&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the kubelets run as containers, you also need to share the StorageOS data
directory into each of the kubelets by adding
&lt;code&gt;--volume=/var/lib/storageos:/var/lib/storageos:rshared&lt;/code&gt; to each of the
kubelets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;title: Install StorageOS as a daemonset with RBAC support
git clone https://github.com/storageos/deploy.git storageos
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos/openshift/deploy-storageos/standard
./deploy-storageos.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or using the Helm chart:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/storageos/helm-chart.git storageos
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos
title: Set cluster.join to hostnames or ip addresses of at least one node
helm install . --name my-release --set cluster.join&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;node01,node02,node03

title: Follow the instructions printed by helm install to update the link between Kubernetes and StorageOS. They look like:
$ &lt;span style=&#34;color:#000&#34;&gt;ClusterIP&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;kubectl get svc/storageos --namespace storageos -o custom-columns&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;IP:spec.clusterIP --no-headers&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
$ &lt;span style=&#34;color:#000&#34;&gt;ApiAddress&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; -n &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;tcp://&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ClusterIP&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;:5705&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; base64&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
$ kubectl patch secret/storageos-api --namespace storageos --patch &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;{\&amp;#34;data\&amp;#34;:{\&amp;#34;apiAddress\&amp;#34;: \&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ApiAddress&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;\&amp;#34;}}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If this is your first installation you may wish to follow the [StorageOS Volume
guide](/docs/platforms/{{ page.platform }}/firstvolume/) for an example of how
to mount a StorageOS volume in a Pod.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubernetes {{ page.k8s-version }}</title>
      <link>/docs/platforms/kubernetes/install/1.12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/install/1.12/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing on OpenShift 3.7</title>
      <link>/docs/platforms/openshift/install/3.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/install/3.7/</guid>
      <description>
        
        
        &lt;p&gt;Running StorageOS as a daemonset is not supported in OpenShift 3.7, but you can
still deploy StorageOS by running directly in Docker.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;title: Install StorageOS managed by systemd, using Ansible
git clone https://github.com/storageos/deploy.git storageos
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos/openshift/deploy-storageos/storageos-ansible-oc-37

title: Update hosts to your hostnames and ip addresses
nano hosts
ansible-playbook -i hosts site.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If this is your first installation you may wish to follow the [StorageOS Volume
guide](/docs/platforms/{{ page.platform }}/firstvolume/) for an example of how
to mount a StorageOS volume in a Pod.&lt;/p&gt;
&lt;p&gt;OpenShift 3.6 and earlier are not supported.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install</title>
      <link>/docs/reference/cluster-operator/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/install/</guid>
      <description>
        
        
        &lt;p&gt;To install the operator follow the installation page for your orchestrator.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;[Kubernetes]({%link _docs/platforms/kubernetes/install/index.md %})&lt;/li&gt;
&lt;li&gt;[OpenShift]({%link _docs/platforms/openshift/install/index.md %})&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install in EKS</title>
      <link>/docs/platforms/aws-eks/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/aws-eks/install/</guid>
      <description>
        
        
        &lt;h1 id=&#34;eks-kubernetes&#34;&gt;EKS Kubernetes&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Only installations of StorageOS with CSI are supported for EKS.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Visit the [best practices page](
{%link _docs/platforms/aws-eks/bestpractices/index.md %}) for production
deployment advice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install StorageOS</title>
      <link>/docs/platforms/azure-aks/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/azure-aks/install/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Only installations of StorageOS with CSI are supported for AKS.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Visit the [best practices page](
{%link _docs/platforms/azure-aks/bestpractices/index.md %}) for production
deployment advice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Install StorageOS</title>
      <link>/docs/platforms/dockeree/install/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/dockeree/install/</guid>
      <description>
        
        
        &lt;p&gt;This section of documentation covers the use of StorageOS in Docker Enterprise Edition.&lt;/p&gt;
&lt;p&gt;Docker EE and the Universal Control Plane can be executed in different Linux
distributions. StorageOS supports RHEL, CentOS, Debian, and selected Ubuntu
images. For more details, check out the supported OS in the [prerequisites page]({%link _docs/prerequisites/systemconfiguration.md %}).&lt;/p&gt;
&lt;p&gt;StorageOS only supports Kubernetes nodes managed by Docker Enterprise Edition,
not those running Swarm. Mixed nodes (those running Kubernetes and Swarm
workloads)  are also not supported.  As a consequence, StorageOS volumes can
only be provisioned on Kubernetes nodes, and only these nodes should be used
for stateful workloads.&lt;/p&gt;
&lt;h1 id=&#34;install-storageos&#34;&gt;Install StorageOS&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link  _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Rancher Catalog</title>
      <link>/docs/platforms/rancher/install/rancher-catalog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/rancher/install/rancher-catalog/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link  _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;StorageOS is a Certified application in the &lt;a href=&#34;https://rancher.com/docs/rancher/v2.x/en/catalog/&#34;&gt;Rancher
Catalog&lt;/a&gt;. You can install
StorageOS using the Rancher application install.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;System&lt;/code&gt; project of your cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-1.png&#34; alt=&#34;install-1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;Apps&lt;/code&gt; tab and click &lt;code&gt;Launch&lt;/code&gt;
&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-2.png&#34; alt=&#34;install-2&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Search for StorageOS and click on the App
&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-3.png&#34; alt=&#34;install-3&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Define the StorageOS cluster installation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A generic configuration for StorageOS is preset using the default values in
the form. The values in the form can be changed to customize the
installation. To customize the installation further, set &lt;code&gt;Install StorageOS Cluster&lt;/code&gt; to false and use a &lt;a href=&#34;/docs/platforms/rancher/install/rancher-catalog#custom-resource-definition&#34;&gt;yaml definition for the StorageOSCluster
Custom
Resource&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;The following options are exposed by the form to allow some simple
customization of the StorageOS installation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[Cluster Operator]({%link _docs/reference/cluster-operator/index.md %}) namespace
: The Kubernetes namespace where the StorageOS Cluster Operator controller
and other resources will be created.&lt;/li&gt;
&lt;li&gt;Container Images
: By default images are pulled from DockerHub, you can specify the image URLs
when using private registries.&lt;/li&gt;
&lt;li&gt;Conditional bootstrap of StorageOS
: Controls the automatic deployment of StorageOS after installing the
Cluster Operator. If set to &lt;code&gt;false&lt;/code&gt;, the Operator will be created, but the
Custom Resource will not be applied to the cluster. Launch the operator and
proceed to the section &lt;a href=&#34;#custom-resource-definition&#34;&gt;Custom Resource
definition&lt;/a&gt;. For more information check the
Operator [documentation]({%link
_docs/reference/cluster-operator/configuration.md %}) and [CR
examples]({%link _docs/reference/cluster-operator/examples.md %}).&lt;/li&gt;
&lt;li&gt;StorageOS namespace
: The Kubernetes namespace where StorageOS will be installed. Installing
into the &lt;code&gt;kube-system&lt;/code&gt; namespace will add StorageOS to a priority class to
ensure high priority resource allocation. Installing StorageOS with the
priority class prevents StorageOS from being evicted during periods of
resource contention.&lt;/li&gt;
&lt;li&gt;Username/Password
: Default Username and Password for the admin account to be created at
StorageOS bootstrap. A random password will be generated by leaving the
field empty or clicking the &lt;code&gt;Generate&lt;/code&gt; button.&lt;/li&gt;
&lt;li&gt;Key-value store [setup]({%link _docs/operations/external-etcd/index.md %})
: Connection and configuration details for an external Etcd cluster.
StorageOS can use an external key-value store to hold configuration.
Settings such as external etcd with TLS termination are available.&lt;/li&gt;
&lt;li&gt;Node Selectors and Tolerations
: Control placement of StorageOS DaemonSet Pods. StorageOS will only be installed
on the selected nodes. Can be used in conjunction with tolerations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-4.png&#34; alt=&#34;install-4&#34;&gt;
&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-5.png&#34; alt=&#34;install-5&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify the cluster bootstrap has successfully completed&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-6.png&#34; alt=&#34;install-6&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;custom-resource-definition&#34;&gt;Custom Resource definition&lt;/h2&gt;
&lt;p&gt;If &lt;code&gt;Install StorageOS Cluster&lt;/code&gt; was set to &lt;code&gt;false&lt;/code&gt;, StorageOS will not be
bootstrapped automatically. After the StorageOS Operator is installed, you can
now create a Custom Resource that describes the StorageOS cluster.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the &lt;code&gt;System Workloads&lt;/code&gt; and &lt;code&gt;Import YAML&lt;/code&gt;
&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-7.png&#34; alt=&#34;install-7&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the &lt;code&gt;Secret&lt;/code&gt; and &lt;code&gt;CustomResource&lt;/code&gt;
&lt;img src=&#34;/images/rancher-ui-green-bubbles/rancher-8.png&#34; alt=&#34;install-8&#34;&gt;&lt;/p&gt;
&lt;p&gt;{% include operator/cr-rancher-ui.md %}&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;{% include operator/first-volume.md  %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Advanced installation on Rancher</title>
      <link>/docs/platforms/rancher/install/rancher-advanced/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/rancher/install/rancher-advanced/</guid>
      <description>
        
        
        &lt;blockquote&gt;
&lt;p&gt;Make sure the
[prerequisites for StorageOS]({%link  _docs/prerequisites/overview.md %}) are
satisfied before proceeding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;{% include operator/manual-install-disclaimer.md %}&lt;/p&gt;
&lt;p&gt;{% include operator/install.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: System Configuration</title>
      <link>/docs/prerequisites/systemconfiguration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/systemconfiguration/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS requires certain kernel modules to function, in particular &lt;a href=&#34;http://linux-iscsi.org/wiki/Main_Page&#34;&gt;Linux-IO
&lt;/a&gt;, an open-source implementation of the
SCSI target.&lt;/p&gt;
&lt;p&gt;We require the following modules to be loaded:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;target_core_mod&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tcm_loop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_core_file&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;configfs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_core_user&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uio&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;N.B. Other applications utilising &lt;a href=&#34;http://linux-iscsi.org/wiki/LIO&#34;&gt;TCMU&lt;/a&gt;
cannot be run concurrently with StorageOS. Doing so may result in corruption
of data. On startup, StorageOS will detect if other applications are using
TCMU and fall back to FUSE. However if StorageOS is started first there is no
mechanism for StorageOS to fallback to FUSE if another application begins to
use TCMU. TCMU can be disabled using the
&lt;a href=&#34;/docs/reference/cluster-operator/configuration&#34;&gt;DISABLE_TCMU&lt;/a&gt;
StorageOSCluster spec parameter.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Depending on the distribution, the modules are shipped as part of the
base kernel package or as part of a kernel extras package which needs to be
installed.&lt;/p&gt;
&lt;h2 id=&#34;distribution-specifics&#34;&gt;Distribution Specifics&lt;/h2&gt;
&lt;p&gt;The following distributions are supported by default:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RHEL 7.5&lt;/li&gt;
&lt;li&gt;CentOS 7&lt;/li&gt;
&lt;li&gt;Debian 9&lt;/li&gt;
&lt;li&gt;Ubuntu Azure&lt;/li&gt;
&lt;li&gt;RancherOS - Note CSI is not supported on RancherOS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ubuntu 16.04/18.04 requires the installation of additional packages.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;N.B. Ubuntu 16.04/18.04 AWS and Ubuntu 18.04 GCE do not provide the
necessary linux-image-extra package - &lt;a href=&#34;/docs/prerequisites/systemconfiguration#ubuntu-on-aws-and-gce&#34;&gt;see
below&lt;/a&gt; for more information&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ubuntu-package-installation&#34;&gt;Ubuntu Package Installation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu 16.04/18.04 Generic&lt;/strong&gt; and &lt;strong&gt;Ubuntu 16.04 GCE&lt;/strong&gt; require extra packages:&lt;/p&gt;
&lt;p&gt;Ubuntu 16.04:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo apt -y update
sudo apt -y install linux-image-extra-&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;uname -r&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ubuntu 18.04+:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo apt -y update
sudo apt -y install linux-modules-extra-&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;uname -r&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ubuntu-with-aws-or-gce-kernels&#34;&gt;Ubuntu With AWS Or GCE Kernels&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ubuntu 16.04/18.04 AWS&lt;/strong&gt; and &lt;strong&gt;Ubuntu 18.04 GCE&lt;/strong&gt; do not yet provide the
linux-image-extra package. As such you should either use &lt;strong&gt;Debian&lt;/strong&gt;, &lt;strong&gt;CentOS&lt;/strong&gt;
or &lt;strong&gt;RHEL&lt;/strong&gt;, or install the non-cloud-provider optimised Ubuntu kernel.&lt;/p&gt;
&lt;p&gt;Installing the non-cloud-provider optimised Ubuntu kernel is something that
should only be done with full understanding of potential ramifications.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo apt -y update
sudo apt install -y linux-virtual linux-image-extra-virtual
sudo apt purge -y linux*aws

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Reboot the machine&lt;/span&gt;
sudo shutdown -r now
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;automatic-configuration&#34;&gt;Automatic Configuration&lt;/h2&gt;
&lt;p&gt;Once required kernel modules are installed on the system, for convenience we
provide a container which will ensure the appropriate modules are loaded and
ready for use at runtime. On Docker installations, you will need to run the
init container prior to starting StorageOS. Our installation guides for
Kubernetes and OpenShift include this step.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Load the required kernel modules. The Kubernetes and OpenShift installations include this step.&lt;/span&gt;
docker run --name enable_lio                  &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;           --privileged                       &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;           --rm                               &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;           --cap-add&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;SYS_ADMIN                &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;           -v /lib/modules:/lib/modules       &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;           -v /sys:/sys:rshared               &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;           storageos/init:0.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;manual-configuration&#34;&gt;Manual Configuration&lt;/h2&gt;
&lt;p&gt;For those wishing to manage their own kernel configuration, rather than using
the init container, perform the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ensure kernel modules are all loaded per list above&lt;/li&gt;
&lt;li&gt;Ensure configfs is loaded and mounted at /sys/kernel/config&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Volume Guide</title>
      <link>/docs/platforms/openshift/volumeguide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/volumeguide/</guid>
      <description>
        
        
        &lt;p&gt;{%include platforms/firstuse.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Volume Guide</title>
      <link>/docs/platforms/rancher/volumeguide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/rancher/volumeguide/</guid>
      <description>
        
        
        &lt;p&gt;{%include platforms/firstuse.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS with EKS Kubernetes best practices</title>
      <link>/docs/platforms/aws-eks/bestpractices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/aws-eks/bestpractices/</guid>
      <description>
        
        
        &lt;p&gt;{% include k8s/bestpractices/dedicated-instancegroup.md %}
{% include k8s/bestpractices/etcd-external.md %}
{% include k8s/bestpractices/api-password.md %}
{% include k8s/bestpractices/storage-host-setup.md %}
{% include k8s/bestpractices/resources.md %}
{% include k8s/bestpractices/private-network.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS with {{ page.platform }} best practices</title>
      <link>/docs/platforms/openshift/bestpractices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/openshift/bestpractices/</guid>
      <description>
        
        
        &lt;p&gt;{% include k8s/bestpractices/pod-placement.md %}
{% include k8s/bestpractices/api-password.md %}
{% include k8s/bestpractices/etcd-external.md %}
{% include k8s/bestpractices/storage-host-setup.md %}
{% include k8s/bestpractices/resources.md %}
{% include k8s/bestpractices/private-network.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Configuration</title>
      <link>/docs/reference/cluster-operator/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/configuration/</guid>
      <description>
        
        
        &lt;p&gt;{% include operator/cr-config-table.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Firewalls</title>
      <link>/docs/prerequisites/firewalls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/firewalls/</guid>
      <description>
        
        
        &lt;h2 id=&#34;port-list&#34;&gt;Port list&lt;/h2&gt;
&lt;p&gt;StorageOS daemons listen on specific ports, which we require to be accessible
between all nodes in the cluster:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Port Number&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;TCP/UDP&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5701&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;gRPC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5702&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Prometheus&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5703&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;DirectFS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5704&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Dataplane health check&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5705&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;REST API&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5706&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ETCD service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5707&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ETCD service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5708&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NATS service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5709&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NATS service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5710&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NATS service&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5711&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;tcp &amp;amp; udp&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Gossip service&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;StorageOS also uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Ephemeral_port&#34;&gt;ephemeral&lt;/a&gt;
ports to dial-out to these ports on other StorageOS nodes. For this reason,
outgoing traffic should be enabled.&lt;/p&gt;
&lt;h2 id=&#34;firewalls-and-vps-providers&#34;&gt;Firewalls and VPS providers&lt;/h2&gt;
&lt;p&gt;Some VPS providers (such as Digital Ocean) ship default firewall rulesets which
must be updated to allow StorageOS to run. Some example rules are shown below -
modify to taste.&lt;/p&gt;
&lt;h3 id=&#34;ufw&#34;&gt;UFW&lt;/h3&gt;
&lt;p&gt;For distributions using UFW, such as RHEL and derivatives:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ufw default allow outgoing
ufw allow 5701:5711/tcp
ufw allow 5711/udp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;firewalld&#34;&gt;Firewalld&lt;/h3&gt;
&lt;p&gt;For distributions that enable firewalld to control iptables such as some installations of OpenShift.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;firewall-cmd --permanent  --new-service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos
firewall-cmd --permanent  --service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos --add-port&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;5700-5800/tcp
firewall-cmd --add-service&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos  --zone&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;public --permanent
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;iptables&#34;&gt;Iptables&lt;/h3&gt;
&lt;p&gt;For those using plain iptables:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Inbound traffic&lt;/span&gt;
iptables -I INPUT -i lo -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit loopback traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -m state --state ESTABLISHED,RELATED -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit established traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p tcp --dport 5701:5711 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;StorageOS&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I INPUT -p udp --dport &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;5711&lt;/span&gt; -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;StorageOS&amp;#39;&lt;/span&gt; -j ACCEPT

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Outbound traffic&lt;/span&gt;
iptables -I OUTPUT -o lo -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit loopback traffic&amp;#39;&lt;/span&gt; -j ACCEPT
iptables -I OUTPUT -d 0.0.0.0/0 -m comment --comment &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Permit outbound traffic&amp;#39;&lt;/span&gt; -j ACCEPT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Please ensure that the iptables rules you have added above come before any
default DROP or REJECT rules.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS Volume Guide</title>
      <link>/docs/platforms/azure-aks/volumeguide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/azure-aks/volumeguide/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/firstuse.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS Volume Guide</title>
      <link>/docs/platforms/dockeree/volumeguide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/dockeree/volumeguide/</guid>
      <description>
        
        
        &lt;p&gt;{%include platforms/firstuse.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS with AKS Kubernetes best practices</title>
      <link>/docs/platforms/azure-aks/bestpractices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/azure-aks/bestpractices/</guid>
      <description>
        
        
        &lt;p&gt;{% include k8s/bestpractices/dedicated-instancegroup.md %}
{% include k8s/bestpractices/etcd-external.md %}
{% include k8s/bestpractices/api-password.md %}
{% include k8s/bestpractices/storage-host-setup.md %}
{% include k8s/bestpractices/resources.md %}
{% include k8s/bestpractices/private-network.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS with {{ page.platform }} best practices</title>
      <link>/docs/platforms/dockeree/bestpractices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/dockeree/bestpractices/</guid>
      <description>
        
        
        &lt;p&gt;{% include k8s/bestpractices/swarm-nodes.md %}
{% include k8s/bestpractices/pod-placement.md %}
{% include k8s/bestpractices/api-password.md %}
{% include k8s/bestpractices/etcd-external.md %}
{% include k8s/bestpractices/storage-host-setup.md %}
{% include k8s/bestpractices/resources.md %}
{% include k8s/bestpractices/private-network.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS with {{ page.platform }} best practices</title>
      <link>/docs/platforms/rancher/bestpractices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/rancher/bestpractices/</guid>
      <description>
        
        
        &lt;p&gt;{% include k8s/bestpractices/pod-placement.md %}
{% include k8s/bestpractices/api-password.md %}
{% include k8s/bestpractices/etcd-external.md %}
{% include k8s/bestpractices/storage-host-setup.md %}
{% include k8s/bestpractices/resources.md %}
{% include k8s/bestpractices/private-network.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Examples</title>
      <link>/docs/reference/cluster-operator/examples/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/examples/</guid>
      <description>
        
        
        &lt;p&gt;{% include operator/examples.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Mount Propagation</title>
      <link>/docs/prerequisites/mountpropagation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/prerequisites/mountpropagation/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS requires mount propagation enabled to present devices as volumes for
containers (see linux kernel documentation
&lt;a href=&#34;http://man7.org/linux/man-pages/man2/mount.2.html&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Certain versions of docker ship with a systemd manifest with
&lt;a href=&#34;https://www.freedesktop.org/software/systemd/man/systemd.exec.html#&#34;&gt;MountFlags&lt;/a&gt; set
to &amp;lsquo;slave&amp;rsquo;, thus preventing StorageOS from working. This can be removed or set
to &amp;lsquo;shared&amp;rsquo; with a systemd drop in:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir -p /etc/systemd/system/docker.service.d/
cat &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;EOF &amp;gt; /etc/systemd/system/docker.service.d/mount_propagation_flags.conf
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;[Service]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;MountFlags=shared
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;EOF&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# systemctl daemon-reload&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# systemctl restart docker.service&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To confirm behaviour, the following command should run without error&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -it --rm -v /mnt:/mnt:shared busybox sh -c /bin/date
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Orchestrators such as Kubernetes or OpenShift have their own ways of exposing
this setting. Kubernetes 1.10 and OpenShift 3.10 have mount propagation enabled by
default. Previous versions require that feature gates are enabled on the
Kubernetes master&amp;rsquo;s &lt;code&gt;controller-manager&lt;/code&gt; and &lt;code&gt;apiserver&lt;/code&gt; services and in the
&lt;code&gt;kubelet&lt;/code&gt; service on each node.&lt;/p&gt;
&lt;p&gt;Installations of orchestrators using Docker require that mount propagation is
enabled for both.&lt;/p&gt;
&lt;p&gt;Refer to our installation pages for the orchestrators to see details on how to
check and enable mount propagation where appropriate.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS Volume Guide</title>
      <link>/docs/platforms/aws-eks/volumeguide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/aws-eks/volumeguide/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/firstuse.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Volume Guide</title>
      <link>/docs/platforms/kubernetes/volumeguide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/volumeguide/</guid>
      <description>
        
        
        &lt;p&gt;{% include platforms/firstuse.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: StorageOS with {{ page.platform }} best practices</title>
      <link>/docs/platforms/kubernetes/bestpractices/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/bestpractices/</guid>
      <description>
        
        
        &lt;p&gt;{% include k8s/bestpractices/pod-placement.md %}
{% include k8s/bestpractices/api-password.md %}
{% include k8s/bestpractices/etcd-external.md %}
{% include k8s/bestpractices/storage-host-setup.md %}
{% include k8s/bestpractices/resources.md %}
{% include k8s/bestpractices/private-network.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cluster Operator Upgrade</title>
      <link>/docs/reference/cluster-operator/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cluster-operator/upgrade/</guid>
      <description>
        
        
        &lt;p&gt;{% include operator/upgrade-uber-yaml.md %}&lt;/p&gt;
&lt;p&gt;{% include operator/upgrade-helm.md %}&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Support</title>
      <link>/docs/support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/support/</guid>
      <description>
        
        
        &lt;p&gt;There are several ways to reach us if you require support. The fastest way to
get in touch is to &lt;a href=&#34;https://slack.storageos.com&#34;&gt;join our public Slack
channel.&lt;/a&gt; &lt;script async defer
src=&#34;http://slack.storageos.com/slackin.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;You can file a support ticket via email to &lt;a href=&#34;mailto:support@storageos.com&#34;&gt;
support@storageos.com&lt;/a&gt;, or use our &lt;a href=&#34;https://support.storageos.com&#34;&gt;Help Desk
portal&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To help us provide effective support, we request that you provide as much
information as possible when contacting us. The list below is a suggested
starting point. Additionally, please include anything specific, such as log
entries, that may help us debug your issue.&lt;/p&gt;
&lt;p&gt;Information about the cluster can be automatically sent to StorageOS engineers
as mentioned in the section &lt;a href=&#34;/docs/support/contactus#storageos-cluster-report&#34;&gt;StorageOS Cluster
Report&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;platform&#34;&gt;Platform&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Cloud provider/Bare metal&lt;/li&gt;
&lt;li&gt;OS distribution and version&lt;/li&gt;
&lt;li&gt;Kernel version&lt;/li&gt;
&lt;li&gt;docker version and installation procedure (distro packages or docker install)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;storageos&#34;&gt;StorageOS&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Version of StorageOS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storageos node ls&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storageos volume ls&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;storageos volume inspect VOL_ID&lt;/code&gt; # in case of issues with a specific volume&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;orchestrator-related-kubernetes-openshift-etc&#34;&gt;Orchestrator related (Kubernetes, OpenShift, etc)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Version and installation method&lt;/li&gt;
&lt;li&gt;Managed or self managed?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl -n storageos get pod&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl -n storageos logs -lapp=storageos -c storageos&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl -n storageos get storageclass&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Specific for your namespaces: &lt;code&gt;kubectl describe pvc PVC_NAME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Specific for your namespaces: &lt;code&gt;kubectl describe pod POD_NAME&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;storageos-cluster-report&#34;&gt;StorageOS Cluster Report&lt;/h2&gt;
&lt;p&gt;StorageOS has a cluster diagnostic function that aggregates cluster information.&lt;/p&gt;
&lt;p&gt;For each node the following is collected:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;StorageOS logs&lt;/li&gt;
&lt;li&gt;output of &lt;code&gt;storageos inspect node&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;output of &lt;code&gt;lshw&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;output of &lt;code&gt;dmesg&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;StorageOS engineers might ask for a report to be generated during
support cases.&lt;/p&gt;
&lt;p&gt;The information given in the cluster report is only used for support purposes
and it will be removed once the data is no longer needed for such purposes.
In case the information is sensitive and can&amp;rsquo;t be given to StorageOS, please
make sure that support engineers have as much information about your
environment as possible.&lt;/p&gt;
&lt;p&gt;The cluster report is created only when a user chooses to do so. For
convenience the report can either be uploaded to StorageOS or downloaded to the
machine running the browser. The report is uploaded from a StorageOS node to a
StorageOS GCP encrypted bucket using a TLS encrypted connection. The upload
takes place only after user confirmation.&lt;/p&gt;
&lt;p&gt;You can generate a report through the StorageOS &lt;a href=&#34;/docs/reference/gui&#34;&gt;GUI&lt;/a&gt; by
navigating to the &lt;code&gt;Cluster&lt;/code&gt; menu. You can also directly connect to the cluster
diagnostic API endpoint and retrieve the bundle. Note that only a user with the
Admin role can create Diagnostic Bundles.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -u &amp;lt;ADMIN_USERNAME&amp;gt;:&amp;lt;ADMIN_PASSWORD&amp;gt; http://&amp;lt;NODE_IP&amp;gt;:5705/v1/diagnostics/cluster -o diagnostic.tar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Self Evaluation Guide</title>
      <link>/docs/self-eval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/self-eval/</guid>
      <description>
        
        
        &lt;p&gt;If you have any specific or more complex requirements please contact StorageOS as we&amp;rsquo;d be happy to organise a POC in conjunction with our Engineering team. You can join our &lt;a href=&#34;https://storageos.slack.com&#34;&gt;slack channel&lt;/a&gt; or email us at: &lt;a href=&#34;mailto:info@storageos.com&#34;&gt;info@storageos.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;
&lt;!-- vscode-markdown-toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#StorageOSOperator&#34;&gt;StorageOS Operator&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#StorageOSOperatorfeatures&#34;&gt;StorageOS Operator features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#NativeDrivervsCSI&#34;&gt;Native Driver vs CSI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ExternalEtcd&#34;&gt;External Etcd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#InstallingStorageOS&#34;&gt;Installing StorageOS&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#Installetcd&#34;&gt;Install etcd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#InstallStorageOSOperator&#34;&gt;Install StorageOS Operator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#InstallStorageOS&#34;&gt;Install StorageOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#SetupaMonitoringStack&#34;&gt;Setup a Monitoring Stack&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#StorageOSFeatures&#34;&gt;StorageOS Features&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#VolumeReplication&#34;&gt;Volume Replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Fencing&#34;&gt;Fencing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Benchmarking&#34;&gt;Benchmarking&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#Considerations&#34;&gt;Considerations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ApplicationvsStorageOSreplication&#34;&gt;Application vs StorageOS replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#StatefulSets&#34;&gt;StatefulSets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#VolumePlacement&#34;&gt;Volume Placement&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#Howtolandavolumeandapodonthesamenode&#34;&gt;How to land a volume and a pod on the same node&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#SyntheticBenchmarks&#34;&gt;Synthetic Benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ApplicationBenchmarks&#34;&gt;Application Benchmarks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#Conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config --&gt;
&lt;!-- /vscode-markdown-toc --&gt;
&lt;div style=&#34;page-break-after: always;&#34;&gt;&lt;/div&gt;
&lt;h2 id=&#34;support-for-self-evaluations&#34;&gt;Support for Self Evaluations&lt;/h2&gt;
&lt;p&gt;Should you have questions or require support, there are several ways to get in
touch with us. The fastest way to get in touch is to &lt;a href=&#34;https://slack.storageos.com&#34;&gt;join our public Slack
channel&lt;/a&gt;. You can also get in touch via email to
&lt;a href=&#34;mailto:support@storageos.com&#34;&gt; info@storageos.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore you can fill out the form below and we will get in touch.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;script charset=&#34;utf-8&#34; type=&#34;text/javascript&#34;
src=&#34;//js.hsforms.net/forms/v2.js&#34;&gt;&lt;/script&gt;
&lt;script&gt;

hbspt.forms.create({

   portalId: &#34;3402546&#34;,
   formId: &#34;a07fecd3-ce5b-4835-b136-51a94a35632b&#34;,
   sfdcCampaignId: &#34;70158000000BAZzAAO&#34;
});
&lt;/script&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;
&lt;p&gt;The first phase of the self-evaluation is to install StorageOS. This section of the document aims to layout what options are exposed to you during installation and why some options may be preferable to you over others.&lt;/p&gt;
&lt;p&gt;A standard StorageOS installations uses the StorageOS operator, so as much of the necessary configuration is handled for you. The StorageOS operator has been certified by &lt;a href=&#34;https://storageos.com/red-hat/&#34;&gt;Red Hat&lt;/a&gt; and is &lt;a href=&#34;https://github.com/storageos/cluster-operator&#34;&gt;open source&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;a-namestorageosoperatorastorageos-operator&#34;&gt;&lt;a name=&#39;StorageOSOperator&#39;&gt;&lt;/a&gt;StorageOS Operator&lt;/h2&gt;
&lt;p&gt;The StorageOS operator is a Kubernetes native application that manages the StorageOS cluster lifecycle. It simplifies cluster installation, cluster removal and other operations.&lt;/p&gt;
&lt;p&gt;The StorageOS operator watches for the creation of StorageOSCluster Custom Resources. A StorageOSCluster is a declarative representation of a StorageOS cluster. For example if CSI is enabled in the StorageOSCluster resource, a StorageOS cluster will be created that uses the CSI driver.&lt;/p&gt;
&lt;h3 id=&#34;a-namestorageosoperatorfeaturesastorageos-operator-features&#34;&gt;&lt;a name=&#39;StorageOSOperatorfeatures&#39;&gt;&lt;/a&gt;StorageOS Operator features&lt;/h3&gt;
&lt;p&gt;Specific configuration options for the StorageOS Operator that we believe to be important during a self-evaluation will be laid out in this guide.&lt;/p&gt;
&lt;p&gt;A set of example StorageOSCluster are listed &lt;a href=&#34;https://docs.storageos.com/docs/reference/cluster-operator/examples&#34;&gt;here&lt;/a&gt;. For an exhaustive list of configuration settings for the StorageOS operator please see our &lt;a href=&#34;https://docs.storageos.com/docs/reference/cluster-operator/configuration&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;a-namenativedrivervscsianative-driver-vs-csi&#34;&gt;&lt;a name=&#39;NativeDrivervsCSI&#39;&gt;&lt;/a&gt;Native Driver vs CSI&lt;/h3&gt;
&lt;p&gt;Communication between Kubernetes and StorageOS can use one of two drivers; the StorageOS Native Driver or the CSI (Container Storage Interface) driver. CSI provides a standardized interface for storage providers to use and is considered GA from Kubernetes 1.13. Therefore, StorageOS uses CSI as the default driver for Kubernetes 1.13+.&lt;/p&gt;
&lt;p&gt;As the StorageOS native driver is implemented in the Kubernetes trunk by StorageOS, it is tied to Kubernetes releases. Whereas using CSI we can iterate more quickly and make improvements independent of Kubernetes releases.&lt;/p&gt;
&lt;p&gt;Importantly CSI is only considered generally available in Kubernetes 1.13+ and is still in technology preview in Openshift 3.11.&lt;/p&gt;
&lt;h2 id=&#34;a-nameexternaletcdaexternal-etcd&#34;&gt;&lt;a name=&#39;ExternalEtcd&#39;&gt;&lt;/a&gt;External Etcd&lt;/h2&gt;
&lt;p&gt;StorageOS highly recommends an external etcd cluster is used for production deployments. In this configuration the etcd cluster would run on separate boxes from the rest of the Kubernetes and StorageOS cluster ensuring stability and resilience of the etcd cluster. However for the purposes of a self-evaluation it is acceptable to run etcd as a container inside Kubernetes.&lt;/p&gt;
&lt;p&gt;We do not recommend running etcd on the same nodes as StorageOS when node failure will be tested, as if the majority of etcd nodes fail then the etcd cluster cannot be recovered automatically. Therefore it is better to run etcd on separate nodes.&lt;/p&gt;
&lt;h2 id=&#34;a-nameprerequisitesaprerequisites&#34;&gt;&lt;a name=&#39;Prerequisites&#39;&gt;&lt;/a&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;StorageOS has some prerequisites that must be met to complete a successful installation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machines intended to run StorageOS have at least 1 CPU core, 2GB RAM&lt;/li&gt;
&lt;li&gt;Docker 1.10 or later with &lt;a href=&#34;https://docs.storageos.com/docs/prerequisites/mountpropagation&#34;&gt;mount propagation enabled&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TCP ports 5701-5710 and TCP &amp;amp; UDP 5711 open between all nodes in the cluster&lt;/li&gt;
&lt;li&gt;A 64bit supported operating system - By default StorageOS supports Debian 9, RancherOS, RHEL7.5 and CentOS7.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Note Ubuntu 16.04 and 18.04 are supported but additional packages are required. Ubuntu 16.04/18.04 with the AWS kernel and Ubuntu 18.04 with the GCE kernel do not provide the required packages and are therefore &lt;em&gt;NOT&lt;/em&gt; supported.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To install the required kernel modules on Ubuntu 16.04:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo apt -y update
sudo apt -y install linux-image-extra-&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;uname -r&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To install the required kernel modules on Ubuntu 18.04+:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;sudo apt -y update
sudo apt -y install linux-modules-extra-&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;uname -r&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;a-nameinstallingstorageosainstalling-storageos&#34;&gt;&lt;a name=&#39;InstallingStorageOS&#39;&gt;&lt;/a&gt;Installing StorageOS&lt;/h2&gt;
&lt;p&gt;Installation steps are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install etcd&lt;/li&gt;
&lt;li&gt;Install StorageOS Operator&lt;/li&gt;
&lt;li&gt;Create a Kubernetes secret detailing the default StorageOS administrator account&lt;/li&gt;
&lt;li&gt;Install StorageOS using a StorageOSCluster Custom Resource&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-nameinstalletcdainstall-etcd&#34;&gt;&lt;a name=&#39;Installetcd&#39;&gt;&lt;/a&gt;Install etcd&lt;/h3&gt;
&lt;p&gt;In order to get a StorageOS cluster stood up quickly, a single node etcd cluster can be installed in Kubernetes, on a Kubernetes master. The reason for installing on a master is that master nodes generally have predictable lifetimes and low Pod scheduling churn. As such there is a lesser risk of the etcd pod being evicted ensuring a stable etcd cluster.&lt;/p&gt;
&lt;p&gt;Note that if the etcd pod is stopped for any reason the etcd cluster will cease to function pending manual intervention. Please take this into account during testing of failure scenarios.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Download repo&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ git clone https://github.com/coreos/etcd-operator.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure NS, Role and RoleBinding&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ROLE_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;etcd-operator
$ &lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;ROLE_BINDING_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;etcd-operator
$ &lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;etcd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create Namespace&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create namespace &lt;span style=&#34;color:#000&#34;&gt;$NAMESPACE&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy Operator&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ./etcd-operator/example/rbac/create_role.sh
$ kubectl -n &lt;span style=&#34;color:#000&#34;&gt;$NAMESPACE&lt;/span&gt; create -f ./etcd-operator/example/deployment.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Kubernetes masters should then be labelled so a nodeSelector can be used in the EtcdCluster manifest&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl label nodes &amp;lt;NODES&amp;gt; etcd-cluster&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos-etcd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once the master node taints are known and the nodes have been labelled you can deploy an EtcdCluster manifest that contains tolerations for all taints on the master nodes and selects for the node label applied in the previous step. A sample manifest is below. Edit the size to match the number of masters you will deploy on and edit the tolerations to match all taints on the master nodes where etcd will be deployed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create the EtcdCluster resource&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n etcd create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: &amp;#34;etcd.database.coreos.com/v1beta2&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: &amp;#34;EtcdCluster&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; name: &amp;#34;storageos-etcd&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; size: 1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; version: &amp;#34;3.3.17&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; pod:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   etcdEnv:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   - name: ETCD_QUOTA_BACKEND&lt;/span&gt;_BYTES
     value: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2147483648&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# 2 GB&lt;/span&gt; 
   - name: ETCD_AUTO_COMPACTION_RETENTION
     value: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;100&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Keep 100 revisions&lt;/span&gt;
   - name: ETCD_AUTO_COMPACTION_MODE
     value: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;revision&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set the revision mode&lt;/span&gt;
   resources:
     requests:
       cpu: 200m
       memory: 300Mi
   securityContext:
     runAsNonRoot: &lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt;
     runAsUser: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;9000&lt;/span&gt;
     fsGroup: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;9000&lt;/span&gt;
   tolerations:
   - operator: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Exists&amp;#34;&lt;/span&gt;
   nodeSelector:
     etcd-cluster: storageos-etcd
   affinity:
     podAntiAffinity:
       preferredDuringSchedulingIgnoredDuringExecution:
       - weight: &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;100&lt;/span&gt;
         podAffinityTerm:
           labelSelector:
             matchExpressions:
             - key: etcd_cluster
               operator: In
               values:
               - storageos-etcd
           topologyKey: kubernetes.io/hostname
END
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;a-nameinstallstorageosoperatorainstall-storageos-operator&#34;&gt;&lt;a name=&#39;InstallStorageOSOperator&#39;&gt;&lt;/a&gt;Install StorageOS Operator&lt;/h2&gt;
&lt;p&gt;In order to install the StorageOS operator download the requisite yaml manifests or apply them with kubectl.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f https://github.com/storageos/cluster-operator/releases/download/1.4.0/storageos-operator.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can verify the operator is running using the following command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -n storageos-operator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;a-nameinstallstorageosainstall-storageos&#34;&gt;&lt;a name=&#39;InstallStorageOS&#39;&gt;&lt;/a&gt;Install StorageOS&lt;/h2&gt;
&lt;p&gt;Once the StorageOS operator has been installed a StorageOS cluster can be generated by creating a StorageOSCluster resource.&lt;/p&gt;
&lt;p&gt;A StorageOSCluster resource describes the state of the StorageOS cluster that is desired and the StorageOS operator will create the desired StorageOS cluster. For examples of StorageOSCluster resources please see our examples page &lt;a href=&#34;https://docs.storageos.com/docs/reference/cluster-operator/examples&#34;&gt;here&lt;/a&gt;. For a full list of the configurable &lt;code&gt;spec&lt;/code&gt; parameters of the StorageOSCluster resource please see &lt;a href=&#34;https://docs.storageos.com/docs/reference/cluster-operator/configuration&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a secret defining the API username and password&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;$&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;kubectl&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;create&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;-f&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;- &amp;lt;&amp;lt;END&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;v1&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;Secret&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos-api&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;labels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;kubernetes.io/storageos&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiUsername&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;c3RvcmFnZW9z&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiPassword&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;c3RvcmFnZW9z&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;END&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a StorageOSCluster resource&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl create -f - &amp;lt;&amp;lt;END
apiVersion: &amp;quot;storageos.com/v1&amp;quot;
kind: StorageOSCluster
metadata:
 name: &amp;quot;storageos&amp;quot;
spec:
 secretRefName: &amp;quot;storageos-api&amp;quot;
 secretRefNamespace: &amp;quot;default&amp;quot;
 images:
   nodeContainer: &amp;quot;storageos/node:1.4.0&amp;quot; # StorageOS version
 resources:
   requests:
   memory: &amp;quot;512Mi&amp;quot;
 csi:
   enable: true
   deploymentStrategy: deployment
 kvBackend:
   address: &#39;storageos-etcd-client.etcd.svc:2379&#39;
   backend: &#39;etcd&#39;
END
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that the cluster has been created and that StorageOS pods are running&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos get pods
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;StorageOS pods enter a ready state after a minimum of 65s has passed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deploy the StorageOS CLI as a container&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos run         &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--image storageos/cli:1.2.2        &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--restart&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;Never                    &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--env &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_HOST&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos     &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--env &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_USERNAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--env &lt;span style=&#34;color:#000&#34;&gt;STORAGEOS_PASSWORD&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;storageos &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;--command cli                      &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;-- /bin/sleep &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;999999&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that StorageOS is working by creating a PVC&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: PersistentVolumeClaim
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; name: pvc-1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; annotations:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   volume.beta.kubernetes.io/storage-class: fast
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; accessModes:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   - ReadWriteOnce
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; resources:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   requests:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     storage: 5Gi
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the CLI is working. &lt;code&gt;pvc-1&lt;/code&gt; should be listed in the CLI output&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it cli -- storageos volume ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The StorageOS web UI can also be used to display information about the state of the cluster. The StorageOS UI can be accessed on any node that is running a StorageOS pod on port 5705. The username/password for the UI is defined by the &lt;code&gt;storageos-api&lt;/code&gt; secret. For this self-evaluation the username/password is &lt;code&gt;storageos:storageos&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;http://&amp;lt;NODE_IP&amp;gt;:5705
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a pod that consumes the PVC&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: Pod
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; name: d1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; containers:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   - name: debian
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     image: debian:9-slim
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     command: [&amp;#34;/bin/sleep&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     args: [ &amp;#34;3600&amp;#34; ]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     volumeMounts:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;       - mountPath: /mnt
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;         name: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; volumes:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   - name: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     persistentVolumeClaim:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;       claimName: pvc-1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that the pod starts successfully. If the pod starts successfully then the StorageOS cluster is working correctly&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pod d1 -w
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The pod mounts a StorageOS volume under &lt;code&gt;/mnt&lt;/code&gt; so any files written there will persist the lifetime of the pod. This can be demonstrated using the following commands.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Execute a shell inside the pod and write some data to a file&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it d1 -- bash
root@d1:/# &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; Hello World! &amp;gt; /mnt/hello
root@d1:/# cat /mnt/hello
Hello World!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delete the pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl delete pod d1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Recreate the pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: Pod
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; name: d1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; containers:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   - name: debian
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     image: debian:9-slim
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     command: [&amp;#34;/bin/sleep&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     args: [ &amp;#34;3600&amp;#34; ]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     volumeMounts:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;       - mountPath: /mnt
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;         name: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt; volumes:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;   - name: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;     persistentVolumeClaim:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;       claimName: pvc-1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open a shell inside the pod and check the contents of &lt;code&gt;/mnt/hello&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it d1 -- cat /mnt/hello
Hello World!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now that StorageOS has been successfully installed, the cluster has a standard license by default which allows for the creation of 100GB of persistent volumes. If you register the cluster then a developer license will be applied and 500GB of persistent volumes can be created. Replicas do not count towards the license total so a 500GB license could be used to created a 500GB volume with 5 replicas. For the purposes of this self-evaluation the standard license is sufficient.&lt;/p&gt;
&lt;h2 id=&#34;a-namesetupamonitoringstackasetup-a-monitoring-stack&#34;&gt;&lt;a name=&#39;SetupaMonitoringStack&#39;&gt;&lt;/a&gt;Setup a Monitoring Stack&lt;/h2&gt;
&lt;p&gt;StorageOS exposes many metrics about the running of StorageOS and perhaps most importantly the read/write performance of StorageOS volumes. Each StorageOS pod exposes a Prometheus endpoint that exposes metrics; these can be visualized with something like Grafana.&lt;/p&gt;
&lt;p&gt;A guided installation of Prometheus, using the Prometheus operator and Grafana, using helm, is available in our deploy repository.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To install Prometheus you can run the &lt;code&gt;install-prometheus&lt;/code&gt; script&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ git clone https://github.com/storageos/use-cases.git storageos-usecases
$ &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-usecases/prometheus
$ ./install-prometheus.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;``&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Grafana can be installed using yaml manifests&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ./install-grafana.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;``&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In order to view the Grafana or Prometheus UI create the NodePort services in the manifests folder&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f manifests/prometheus/prometheus-svc.yaml.example
$ kubectl create -f manifests/grafana/grafana-svc.yaml.example
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;
The Grafana UI is then available on `&amp;lt;NODE_IP&amp;gt;:3000`. The username and password are `admin`:`admin`. The username and password are set in a secret in the grafana-deployment.yaml file. Once logged in create the Prometheus data source by setting the URL to `http://prometheus-operated:9090` and configure the scrape interval to be 10s and set the query timeout to 30s. The [StorageOS example dashboard](https://grafana.com/dashboards/10093) can then be imported into Grafana.

&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To confirm the dashboard is working try writing some data to the volume that was created previously&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it d1 -- bash -c &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;dd if=/dev/zero of=/mnt/file count=1024 bs=1M oflag=direct&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;``&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The StorageOS dashboard will show that a volume is being written to, giving metrics for IOPS and bandwidth.&lt;/p&gt;
&lt;p&gt;For more information about how to interpret the metrics that we expose please see our documentation about &lt;a href=&#34;https://docs.storageos.com/docs/operations/monitoring/&#34;&gt;Monitoring StorageOS&lt;/a&gt;. And for a full overview of the metrics that we expose please refer to our &lt;a href=&#34;https://docs.storageos.com/docs/reference/prometheus&#34;&gt;Prometheus&lt;/a&gt; documentation.&lt;/p&gt;
&lt;p&gt;We have also created a dashboard for monitoring etcd pods which can be found &lt;a href=&#34;https://grafana.com/dashboards/10323&#34;&gt;here&lt;/a&gt;. It is important to defragment etcd before the on disk space exceeds the database quota, see the &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/maintenance.md#defragmentation&#34;&gt;etcd documentation&lt;/a&gt; for more information about etcd maintenance.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1 id=&#34;a-namestorageosfeaturesastorageos-features&#34;&gt;&lt;a name=&#39;StorageOSFeatures&#39;&gt;&lt;/a&gt;StorageOS Features&lt;/h1&gt;
&lt;p&gt;Now that you have a correctly functioning StorageOS cluster we will explain some of our features that may be of use to you as you complete application and synthetic benchmarks.&lt;/p&gt;
&lt;p&gt;StorageOS features are all enabled/disabled by applying labels to volumes. These labels can be passed to StorageOS via persistent volume claims (PVCs) or can be applied to volumes using the StorageOS CLI or GUI.&lt;/p&gt;
&lt;p&gt;The following is not an exhaustive feature list but outlines features which are commonly of use during a self-evaluation.&lt;/p&gt;
&lt;h2 id=&#34;a-namevolumereplicationavolume-replication&#34;&gt;&lt;a name=&#39;VolumeReplication&#39;&gt;&lt;/a&gt;Volume Replication&lt;/h2&gt;
&lt;p&gt;StorageOS enables synchronous replication of volumes using the &lt;code&gt;storageos.com/replicas&lt;/code&gt; label.&lt;/p&gt;
&lt;p&gt;The volume that is active is referred to as the master volume. The master volume and its replicas are always placed on separate nodes. In fact if a replica cannot be placed on a node without a replica of the same volume, the volume will fail to be created. For example, in a three node StorageOS cluster a volume with 3 replicas cannot be created as the third replica cannot be placed on a node that doesn&amp;rsquo;t already contain a replica of the same volume.&lt;/p&gt;
&lt;p&gt;The failure mode for a volume affects how many failed replicas can be tolerated before the volume is marked as offline. Replicas are also segregated according to the &lt;code&gt;iaas/failure-domains&lt;/code&gt; node label. StorageOS will automatically place a master volume and its replicas in separate failure domains where possible.&lt;/p&gt;
&lt;p&gt;See our &lt;a href=&#34;https://docs.storageos.com/docs/concepts/replication&#34;&gt;replication documentation&lt;/a&gt; for more information on volume replication.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To test volume replication create the following PersistentVolumeClaim&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: PersistentVolumeClaim
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;name: pvc-replicated
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;labels:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  storageos.com/replicas: &amp;#34;1&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;annotations:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  volume.beta.kubernetes.io/storage-class: fast
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;accessModes:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  - ReadWriteOnce
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;resources:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  requests:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    storage: 5Gi
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Note that volume replication is enabled by setting the &lt;code&gt;storageos.com/replicas&lt;/code&gt; label on the volume.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that a replicated volume has been created by using the StorageOS CLI or UI&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it cli -- storageos volume ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a pod that uses the PVC&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f - &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;END
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;apiVersion: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;kind: Pod
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;metadata:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;name: replicated-pod
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;spec:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;containers:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  - name: debian
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    image: debian:9-slim
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    command: [&amp;#34;/bin/sleep&amp;#34;]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    args: [ &amp;#34;3600&amp;#34;  ]
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    volumeMounts:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;      - mountPath: /mnt
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;        name: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;volumes:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  - name: v1
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;    persistentVolumeClaim:
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;      claimName: pvc-replicated
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;END&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Write data to the volume&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it replicated-pod -- bash
root@replicated-pod:/# &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; Hello World! &amp;gt; /mnt/hello
root@replicated-pod:/# cat /mnt/hello
Hello World!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the location of the master volume and drain the node using the StorageOS CLI. Draining a node causes all volumes on the node to be evicted. For replicated volumes this immediately promotes a replica to become the new master, and for unreplicated volumes a replica is created and fully synchronized before the volume fails over&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pvc
NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
pvc-replicated Bound    pvc-29e2ad6e-8c4e-11e9-8356-027bfbbece86   5Gi        RWO            fast           1m

$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it -n storageos cli -- storageos volume ls
NAMESPACE/NAME                                    SIZE   MOUNT           STATUS  REPLICAS  LOCATION
default/pvc-29e2ad6e-8c4e-11e9-8356-027bfbbece86  50GiB  ip-10-0-11-175  active  1/1       ip-10-0-11-167 &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;healthy&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;

$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it -n storageos cli -- storageos node drain ip-10-0-11-167
ip-10-0-11-167
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the location of the master volume and notice that it is on a new node&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it -n storageos cli -- storageos volume ls
NAMESPACE/NAME                                    SIZE   MOUNT           STATUS  REPLICAS  LOCATION
default/pvc-29e2ad6e-8c4e-11e9-8356-027bfbbece86  50GiB  ip-10-0-11-175  active  1/1       ip-10-0-11-189 &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;synching&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that the data is still accessible to the pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it replicated-pod -- bash
root@replicated-pod:/# cat /mnt/hello
Hello World!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;a-namefencingafencing&#34;&gt;&lt;a name=&#39;Fencing&#39;&gt;&lt;/a&gt;Fencing&lt;/h2&gt;
&lt;p&gt;StorageOS enables fencing of pods using the &lt;code&gt;storageos.com/fenced=true&lt;/code&gt; label. Pods must have the fencing label set and be using at least one StorageOS volume. Any StorageOS volume that the pod is using must have at least one healthy replica.&lt;/p&gt;
&lt;p&gt;StatefulSets are the de facto controller for stateful workloads in Kubernetes. They provide a variety of useful guarantees but chief among them is that pods are unique. This guarantee means that if Kubernetes detects that a node is segregated from the master, StatefulSet pods will not be rescheduled unless the StatefulSet pods on the failed node are manually force terminated. However as StorageOS pods communicate via a gossip protocol, StorageOS can determine whether the node is truly offline or just partitioned from the master. In the case that the node is no longer participating in gossip, StorageOS can intervene and terminate StatefulSet pods that are using StorageOS volumes thus improving the time to recover for StatefulSets.&lt;/p&gt;
&lt;p&gt;For more information about StatefulSets and fencing please see our &lt;a href=&#34;https://docs.storageos.com/docs/concepts/fencing&#34;&gt;Fencing concepts&lt;/a&gt; page. For information on how to enable Fencing see our &lt;a href=&#34;https://docs.storageos.com/docs/operations/fencing&#34;&gt;Fencing operations&lt;/a&gt; page.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To test fencing create a StatefulSet from the StorageOS deploy repository. Note this is the same repository that we cloned earlier so if you already have a copy just &lt;code&gt;cd storageos-usecases&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ git clone https://github.com/storageos/use-cases.git storageos-usecases
$ &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-usecases
$ kubectl create -f ./fencing
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check what node the &lt;code&gt;mysql-0&lt;/code&gt; pod is running on and make that node unavailable e.g. shutdown the node or stop the kubelet on the node. Now watch as the &lt;code&gt;mysql-0&lt;/code&gt; pod is rescheduled onto a different node&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;mysql -o wide
NAME      READY   STATUS    RESTARTS   AGE    IP           NODE                           NOMINATED NODE   READINESS GATES
client    1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          1m     10.244.2.4   ip-10-1-10-112.storageos.net   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
mysql-0   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          1m     10.244.1.6   ip-10-1-10-235.storageos.net   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the node is in a NotReady state you&amp;rsquo;ll see that the &lt;code&gt;mysql-0&lt;/code&gt; pod has been rescheduled on a different node&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get nodes
NAME                           STATUS     ROLES    AGE    VERSION
ip-10-1-10-112.storageos.net   Ready      master   107m   v1.14.3
ip-10-1-10-118.storageos.net   Ready      &amp;lt;none&amp;gt;   107m   v1.14.3
ip-10-1-10-235.storageos.net   NotReady   &amp;lt;none&amp;gt;   107m   v1.14.3


$ kubectl get pods -o wide
NAME      READY   STATUS        RESTARTS   AGE   IP           NODE                           NOMINATED NODE   READINESS GATES
client    1/1     Running       &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          1m    10.244.2.4   ip-10-1-10-112.storageos.net   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
mysql-0   1/1     Running       &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          30s   10.244.1.6   ip-10-1-10-118.storageos.net   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1 id=&#34;a-namebenchmarkingabenchmarking&#34;&gt;&lt;a name=&#39;Benchmarking&#39;&gt;&lt;/a&gt;Benchmarking&lt;/h1&gt;
&lt;p&gt;As a rule the best performance is obtained by using unreplicated volumes that are co-located with the application or benchmarking tool writing to the volume. See Volume Placement below for more information.&lt;/p&gt;
&lt;p&gt;When running benchmarks in the cloud, benchmarks need to be run multiple times and nodes should be destroyed and recreated so that the underlying machine changes. This should be done to reduce the impact that noisy neighbours might have on benchmark results.&lt;/p&gt;
&lt;h2 id=&#34;a-nameconsiderationsaconsiderations&#34;&gt;&lt;a name=&#39;Considerations&#39;&gt;&lt;/a&gt;Considerations&lt;/h2&gt;
&lt;h3 id=&#34;a-nameapplicationvsstorageosreplicationaapplication-vs-storageos-replication&#34;&gt;&lt;a name=&#39;ApplicationvsStorageOSreplication&#39;&gt;&lt;/a&gt;Application vs StorageOS replication&lt;/h3&gt;
&lt;p&gt;Certain applications are able to natively replicate or shard data between application instances. When using these applications it is worth considering whether application replication, StorageOS replication or a mixture of both should be used.&lt;/p&gt;
&lt;p&gt;When StorageOS replication is enabled the time to recover in cases of node failure can be lessened. This is because StorageOS will promote a replica, Kubernetes will reschedule the application instance and the amount of data the application needs to catch up on is limited to whatever data was modified while the application was being rescheduled. Without StorageOS replication the application would have to rebuild an entire copy of data. Some applications have their performance greatly impacted by having to rebuild shards/replicas so this is also avoided.&lt;/p&gt;
&lt;h3 id=&#34;a-namestatefulsetsastatefulsets&#34;&gt;&lt;a name=&#39;StatefulSets&#39;&gt;&lt;/a&gt;StatefulSets&lt;/h3&gt;
&lt;p&gt;StatefulSets are the de facto controller for stateful applications. As such, when deploying applications that will use StorageOS volumes, StatefulSets should be used. You can find more information about StatefulSets &lt;a href=&#34;https://docs.storageos.com/docs/usecases/kubernetes/#statefulsets&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;a-namevolumeplacementavolume-placement&#34;&gt;&lt;a name=&#39;VolumePlacement&#39;&gt;&lt;/a&gt;Volume Placement&lt;/h3&gt;
&lt;p&gt;StorageOS volumes give the best performance when the application pod and the master volume are co-located on the same node. When benchmarking applications, it is useful to take into account that using remote volumes and replicas impact the overall performance of a volume.&lt;/p&gt;
&lt;p&gt;Going from 0 to 1 replica has the greatest performance impact for writes as now the latency of the operation is equal to the round trip time to the node with the replica over the network. Adding additional replicas poses less of a performance impact as writes to replicas are done in parallel, and the round trip time to each node is unlikely to greatly increase unless replicas land on nodes that are geographically distant to the master volumes&amp;rsquo; node.&lt;/p&gt;
&lt;p&gt;Even when volumes are replicated co-location of pod and master volume is still desirable because application writes are first sent to the master and then sent from the master volume to the replicas. Writing to a local master therefore saves network latency between the application and the master volume. As reads are always served from the master volume a remote master volume will add latency to reads as well as writes.&lt;/p&gt;
&lt;p&gt;When testing applications, such as databases, it is also necessary to run benchmarks for a sufficiently long time to account for caching, and cache flushing that databases do. We recommend running application benchmarks over a 20-30min period for this reason.&lt;/p&gt;
&lt;h4 id=&#34;a-namehowtolandavolumeandapodonthesamenodeahow-to-land-a-volume-and-a-pod-on-the-same-node&#34;&gt;&lt;a name=&#39;Howtolandavolumeandapodonthesamenode&#39;&gt;&lt;/a&gt;How to land a volume and a pod on the same node&lt;/h4&gt;
&lt;p&gt;StorageOS has an automatic co-location feature on our development roadmap that we are calling pod locality. Until the feature is GA co-location of a master volume and a pod can be achieved by leveraging existing StorageOS and Kubernetes features.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;storageos.com/hint.master&lt;/code&gt; is a volume label that influences the placement of a StorageOS master volume. By setting this label to the same value as a &lt;code&gt;nodeSelector&lt;/code&gt; on a StatefulSet or Pod the master volume and the pod should co-locate on the same node. You can reference our &lt;a href=&#34;https://github.com/storageos/use-cases/blob/master/FIO/local-volumes/jobs/fio-4vol.yaml&#34;&gt;FIO local volumes job&lt;/a&gt; for an example of how to do this.&lt;/p&gt;
&lt;p&gt;StorageOS &lt;a href=&#34;https://docs.storageos.com/docs/concepts/pools&#34;&gt;Pools&lt;/a&gt; can be used to restrict volume placement to a subset of nodes. Nodes can be included in a specific pool by matching a pools &lt;code&gt;nodeSelector&lt;/code&gt;. Pools can be created using the StorageOS GUI or &lt;a href=&#34;https://docs.storageos.com/docs/reference/cli/pool&#34;&gt;CLI&lt;/a&gt;. The pool that a volume will be created from is specified in the StorageClass &lt;code&gt;pool&lt;/code&gt; &lt;a href=&#34;https://github.com/storageos/deploy/blob/master/k8s/examples/000-storageclass.yaml&#34;&gt;parameter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is also possible to cordon StorageOS nodes using the GUI or the CLI in order to force the placement of volumes on a specific node. A further possibility is to use of the &lt;code&gt;storageos.com/auto-follow&lt;/code&gt; label. This label enables StorageOS to promote a replica volume to being a master when the pod and the replica volume are co-located.
 &lt;/p&gt;
&lt;h2 id=&#34;a-namesyntheticbenchmarksasynthetic-benchmarks&#34;&gt;&lt;a name=&#39;SyntheticBenchmarks&#39;&gt;&lt;/a&gt;Synthetic Benchmarks&lt;/h2&gt;
&lt;p&gt;Synthetic benchmarks using tools such as FIO are a useful way to begin measuring StorageOS performance. While not fully representative of application performance, they allow us to reason about the performance of storage devices without the added complexity of simulating real world workloads, and provide results easily comparable across platforms.&lt;/p&gt;
&lt;p&gt;As with application benchmarks, when testing in public clouds multiple runs on newly created nodes should be considered to account for the impact of noisy neighbours.&lt;/p&gt;
&lt;p&gt;StorageOS has created a test suite for running FIO tests against StorageOS volumes that can be found &lt;a href=&#34;https://github.com/storageos/use-cases/tree/master/FIO&#34;&gt;here&lt;/a&gt;. The test suite can be deployed into a Kubernetes cluster using the instructions below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Clone the StorageOS use cases repo.  Note this is the same repository that we cloned earlier so if you already have a copy just &lt;code&gt;cd storageos-usecases/FIO/local-volumes&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ git clone https://github.com/storageos/use-cases.git storageos-usecases
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move into the FIO local-volumes folder&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-usecases/FIO/local-volumes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get the name of the node that you wish the FIO pods and volumes to be created on. Make sure that the node name and the label &lt;code&gt;kubernetes.io/hostname&lt;/code&gt; match and that the node has enough storage capacity to create 8Gi worth of volumes&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get node --show-labels
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate the FIO jobs by passing in the node name that the job should run on. The number is the number of volumes that FIO will test concurrently&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ./job-generator-per-volumecount.sh &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;$NODE_NAME&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upload the FIO profiles as ConfigMaps&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ./upload-fio-profiles.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the FIO tests&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f ./jobs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the PVCs have been provisioned&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pvc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the StorageOS CLI to check the location of the volumes&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; cli -- storageos volume ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify that the Pod is running on the same node&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pod -owide
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;FIO has a number of parameters that can be adjusted to simulate a variety of workloads and configurations. Particularly the queue depth, block size and the number of volumes used affect the FIO results. To tune the FIO parameters the profiles file can be edited or the ConfigMap that is created from the profiles file can be edited directly.&lt;/p&gt;
&lt;p&gt;StorageOS configuration also affects the overall volume performance. For example adding a replica to a volume will increase the latency for writes and affect IOPS and bandwidth for the volume.&lt;/p&gt;
&lt;p&gt;To see the effect a StorageOS replica has on performance rerun an FIO test but add the &lt;code&gt;storageos.com/replicas: &amp;quot;1&amp;quot;&lt;/code&gt; label to the PersistentVolumeClaims in the jobs spec. The greatest performance impact from adding replicas comes when moving from 0 to 1 replica. Adding additional replicas does not incur a significant performance penalty.&lt;/p&gt;
&lt;p&gt;The remote volumes folder contains a guide for performing the same FIO tests against remote volumes.
 &lt;/p&gt;
&lt;h2 id=&#34;a-nameapplicationbenchmarksaapplication-benchmarks&#34;&gt;&lt;a name=&#39;ApplicationBenchmarks&#39;&gt;&lt;/a&gt;Application Benchmarks&lt;/h2&gt;
&lt;p&gt;While synthetic benchmarks are useful for examining the behaviour of StorageOS with very specific workloads, in order to get a realistic picture of StorageOS performance actual applications should be tested.&lt;/p&gt;
&lt;p&gt;Many applications come with test suites which provide standard workloads. For best results, test using your application of choice with a representative configuration and real world data.&lt;/p&gt;
&lt;p&gt;As an example of benchmarking an application the following steps lay out how to benchmark a Postgres database backed by a StorageOS volume.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Start by cloning the StorageOS use cases repository. Note this is the same repository that we cloned earlier so if you already have a copy just &lt;code&gt;cd storageos-usecases/pgbench&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ git clone https://github.com/storageos/use-cases.git storageos-usecases
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move into the Postgres examples folder&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-usecases/pgbench
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Decide which node you want the pgbench pod and volume to be located on. The node needs to be labelled &lt;code&gt;app=postgres&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl label node &amp;lt;NODE&amp;gt; &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;postgres
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then set the &lt;code&gt;storageos.com/hint.master&lt;/code&gt; label in 20-postgres-statefulset.yaml file to match the node name you have chosen before creating all the files&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that Postgres is up and running&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -w -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;postgres
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use the StorageOS CLI or the GUI to check the master volume location and the mount location. They should match&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n storageos &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it cli -- storageos v ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exec into the pgbench container and run pgbench&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it pgbench -- bash -c &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;/opt/cpm/bin/start.sh&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1 id=&#34;a-nameconclusionaconclusion&#34;&gt;&lt;a name=&#39;Conclusion&#39;&gt;&lt;/a&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;After completing these steps you will have benchmark scores for StorageOS. Please keep in mind that benchmarks are only part of the story and that there is no replacement for testing actual production or production like workloads.&lt;/p&gt;
&lt;p&gt;StorageOS invites you to provide feedback on your self-evaluation to the &lt;a href=&#34;https://storageos.slack.com&#34;&gt;slack channel&lt;/a&gt; or by directly emailing us at &lt;a href=&#34;mailto:info@storageos.com&#34;&gt;info@storageos.com&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: </title>
      <link>/docs/operations/updates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/operations/updates/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: API Reference</title>
      <link>/docs/reference/api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/api/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS Control plane API is accessible either through port 80 or 8000.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Architecture</title>
      <link>/docs/concepts/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/architecture/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS is a software-defined storage platform for running stateful
applications in containers.&lt;/p&gt;
&lt;p&gt;Read about &lt;a href=&#34;https://storageos.com/storageos-cloud-native-storage&#34;&gt;the cloud native storage principles behind
StorageOS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fundamentally, StorageOS aggregates storage attached to nodes in a cluster,
creates a virtual pool across nodes, and presents virtual volumes from the pool
into containers.&lt;/p&gt;
&lt;p&gt;It is agnostic to the underlying storage and runs equally on
bare metal, in virtual machines or on cloud providers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/docs/concepts/storageos-cluster.png&#34; alt=&#34;StorageOS architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;StorageOS is deployed as one container on each node that presents or consumes
storage, available as &lt;code&gt;storageos/node&lt;/code&gt; on the Docker Hub. In Kubernetes,
this is typically managed as a daemonset, next
to the applications. StorageOS runs entirely in user space.&lt;/p&gt;
&lt;p&gt;StorageOS is designed to feel familiar to Kubernetes and Docker users. Storage
is managed through standard StorageClasses and PersistentVolumeClaims, and
features are controlled by Kubernetes-style labels and selectors, prefixed with
&lt;code&gt;storageos.com/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;StorageOS uses the storage capacity from the nodes where it is installed to
provide thinly-provisioned volumes. That space is selected from the mount point
of &lt;code&gt;/var/lib/storageos/data&lt;/code&gt; on the host. It is recommended that disk devices
are used exclusively for StorageOS, as described in [Managing Host Storage
]({%link _docs/operations/managing-host-storage.md %})&lt;/p&gt;
&lt;p&gt;Any container may mount a StorageOS virtual volume from any node, regardless of
whether the container and volume are colocated on the same node or the volume is
remote. Therefore, applications may be started or restarted on any node and
access volumes transparently.&lt;/p&gt;
&lt;p&gt;Volumes are provisioned from a storage pool and are thinly provisioned.&lt;/p&gt;
&lt;p&gt;By default, volumes are cached to improve read performance and compressed to
reduce network traffic.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Available memory&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;% of overall memory reserved by StorageOS for caching&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;3 GB or less&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;3-8 GB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;8-12 GB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;12 GB or more&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Backing up files from StorageOS volumes</title>
      <link>/docs/usecases/backups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/usecases/backups/</guid>
      <description>
        
        
        &lt;p&gt;In this example use case we provide three different strategies for accessing
files that have been written to a StorageOS  persistent volume.&lt;/p&gt;
&lt;p&gt;In the following examples the &amp;ldquo;application&amp;rdquo; container is the container &lt;code&gt;main&lt;/code&gt;,
which has a rsync, &lt;a href=&#34;https://www.nginx.com/&#34;&gt;Nginx&lt;/a&gt; or sftp sidecar container. The StorageOS volume that
the application is writing to will be mounted into the sidecar container so
files written by the application are available for export. Files can be
exported using Nginx as a web file server, transferred using rsync or accessed
via SFTP.&lt;/p&gt;
&lt;p&gt;The files create a stateful set that can be used &lt;em&gt;AFTER&lt;/em&gt; a StorageOS cluster
has been created. [See our guide on how to install StorageOS on Kubernetes for more
information]({% link _docs/platforms/kubernetes/install/index.md %}).&lt;/p&gt;
&lt;h2 id=&#34;clone-repository&#34;&gt;Clone Repository&lt;/h2&gt;
&lt;p&gt;In order to deploy the examples, clone this repository and use kubectl to create the
Kubernetes objects.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ git clone https://github.com/storageos/use-cases.git storageos-usecases
$ &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-usecases/backup
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Before deploying the backup-example stateful set we recommend looking
through the examples to understand how the different containers are
configured&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;exfiltrating-files-through-http&#34;&gt;Exfiltrating files through HTTP&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Deploy the Nginx example&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f nginx/
service/backup-example created
configmap/nginx-config created
statefulset.apps/backup-example created
pod/busybox created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Check that a backup-example pod is running&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -w -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;backup-example-nginx
   NAME        READY    STATUS    RESTARTS    AGE
   backup-example-0     1/1      Running    &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          1m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Exec into the &lt;code&gt;main&lt;/code&gt; container and write some data to a file&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it backup-example-nginx-0 -c main bash
root@backup-example-0:/# &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;date&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt; &amp;gt; /data/date.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Check that the service exists&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get svc backup-example-nginx
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   AGE
backup-example-nginx   ClusterIP   100.65.18.199   &amp;lt;none&amp;gt;        80/TCP    46s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Use wget to access the files served by Nginx. Nginx is sharing files from
the same volume that the &lt;code&gt;main&lt;/code&gt; application container is writing to. The
connection to the Nginx container is made via the backup-example service.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it busybox -- /bin/wget -q -O- http://backup-example-nginx
    &amp;lt;html&amp;gt;
    &amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Index of /&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
    &amp;lt;h1&amp;gt;Index of /&amp;lt;/h1&amp;gt;&amp;lt;hr&amp;gt;&amp;lt;pre&amp;gt;&amp;lt;a &lt;span style=&#34;color:#000&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;../&amp;#34;&lt;/span&gt;&amp;gt;../&amp;lt;/a&amp;gt;
    &amp;lt;a &lt;span style=&#34;color:#000&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;lost%2Bfound/&amp;#34;&lt;/span&gt;&amp;gt;lost+found/&amp;lt;/a&amp;gt;
    12-Feb-2019 12:32                   -
    &amp;lt;a &lt;span style=&#34;color:#000&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;date.txt&amp;#34;&lt;/span&gt;&amp;gt;date.txt&amp;lt;/a&amp;gt;
    12-Feb-2019 12:49                  &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;29&lt;/span&gt;
    &amp;lt;/pre&amp;gt;&amp;lt;hr&amp;gt;&amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it busybox -- /bin/wget -q -O- http://backup-example-nginx/date.txt
Tue Feb &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;12&lt;/span&gt; 12:49:15 UTC &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2019&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Depending on what files have been written to the StorageOS volume the output of
the index file will be different. In the example the date.txt file we created
in Step 2 is present on the volume.&lt;/p&gt;
&lt;h2 id=&#34;exfiltrating-files-through-rsync&#34;&gt;Exfiltrating files through Rsync&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Deploy the rsync example&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f rsync/
service/backup-example created
configmap/rsync-config created
secret/rsync-credentials created
statefulset.apps/backup-example created
pod/rsync created
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Check that a backup-example pod is running&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -w -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;backup-example-rsync
   NAME        READY    STATUS    RESTARTS    AGE
   backup-example-0     1/1      Running    &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          1m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Exec into the &lt;code&gt;main&lt;/code&gt; container and write some data to a file&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it backup-example-rsync-0 -c main bash
root@backup-example-0:/# &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;date&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt; &amp;gt; /data/date.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Check that the service exists&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get svc backup-example-rsync
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   AGE
backup-example-rsync   ClusterIP   100.65.18.199   &amp;lt;none&amp;gt;        873/TCP    46s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Use rsync to access the files shared by the rsync daemon. rsync is sharing
files from the same volume that the &lt;code&gt;main&lt;/code&gt; container is writing to. A
username and password that are set in the rsync-credentials secret. The
secret supplied in the example has the username and password set to username
and password.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl exec -it rsync sh
/ # rsync --list-only rsync://username@backup-example-rsync/share
Password:
drwxr-xr-x          4,096 2019/02/12 12:49:15 .
-rw-r--r--             29 2019/02/12 12:49:15 date.txt
drwx------         16,384 2019/02/12 12:32:40 lost+found
/ # rsync -chavzP rsync://username@backup-example-rsync/share/date.txt .
Password:
receiving incremental file list
date.txt
             29 100%   28.32kB/s    0:00:00 (xfr#1, to-chk=0/1)

             sent 43 bytes  received 135 bytes  50.86 bytes/sec
             total size is 29  speedup is 0.16
/ # cat date.txt
Tue Feb 12 12:49:15 UTC 2019
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the example above the list of available files was shown and a file called
date.txt was synchronized to the rsync container.&lt;/p&gt;
&lt;h2 id=&#34;exfiltrating-files-through-sftp&#34;&gt;Exfiltrating files through SFTP&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Deploy the sftp example&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl create -f sftp/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Exec into the &lt;code&gt;main&lt;/code&gt; container and write some data to a file&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it backup-example-sftp-0 -c main bash
root@backup-example-0:/# &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;date&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt; &amp;gt; /data/date.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Check that the service exists&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get svc backup-example-sftp
NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;   AGE
backup-example-sftp   ClusterIP   100.70.50.56   &amp;lt;none&amp;gt;        22/TCP    2h
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;Use SFTP to access the files shared by the SFTP container. If you have made
no changes to the sftp-config secret the password is password.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it sftp -- bash
root@sftp:/# sftp alex@backup-example-sftp
alex@backup-example-sftp&lt;span style=&#34;color:#a40000&#34;&gt;&amp;#39;&lt;/span&gt;s password:
Connected to backup-example-sftp.
sftp&amp;gt; ls
date.txt    lost+found
sftp&amp;gt; get date.txt
Fetching /date.txt to date.txt
/date.txt
100%   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;29&lt;/span&gt;    15.9KB/s   00:00
sftp&amp;gt; bye
root@sftp:/# cat date.txt
Tue Feb &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;12&lt;/span&gt; 17:51:32 UTC &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2019&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to do this a SFTP user needs to be configured. The details for the
user are stored in the sftp-config secret (see &lt;code&gt;sftp/17-secret.yaml&lt;/code&gt;). The secret
consists of base64 encoded username:password:uid:guid and the user is chroot&amp;rsquo;ed
inside their home directory so the mount point for the StorageOS volume in the
SFTP container in &lt;code&gt;sftp/20-backup-pod.yaml&lt;/code&gt; needs to be configured.&lt;/p&gt;
&lt;h3 id=&#34;using-custom-ssh-keys&#34;&gt;Using custom SSH Keys&lt;/h3&gt;
&lt;p&gt;The ConfigMap ssh-key-pub (see &lt;code&gt;sftp/15-configmap.yaml&lt;/code&gt;) needs to be populated with a
public key. The corresponding private key needs to be base64 encoded and put
into the ssh-key-private secret (see &lt;code&gt;sftp/17-secret.yaml&lt;/code&gt;). The user to connect as is
determined by the user that is configured in the sftp-config configMap. To
restrict logins to the SSH key edit the sftp-config secret so it contains no
password (user::uid:guid).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Connect to the sftp pod and connect through the service to the SFTP container
running inside the backup-example pod.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it sftp -- bash
root@sftp:/# sftp -i /home/alex/.ssh/id_rsa alex@backup-example-sftp
Connected to backup-example-sftp.
sftp&amp;gt; ls
date.txt    lost+found
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Cassandra</title>
      <link>/docs/platforms/kubernetes/examples/cassandra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/platforms/kubernetes/examples/cassandra/</guid>
      <description>
        
        
        &lt;h1 id=&#34;imageimagesdocsexplorecassandralogopng-cassandra-with-storageos&#34;&gt;&lt;img src=&#34;/images/docs/explore/cassandralogo.png&#34; alt=&#34;image&#34;&gt; Cassandra with StorageOS&lt;/h1&gt;
&lt;p&gt;Cassandra is a popular distributed NoSQL open source database.&lt;/p&gt;
&lt;p&gt;Before you start, ensure you have StorageOS installed and ready on a Kubernetes
cluster. [See our guide on how to install StorageOS on Kubernetes for more
information]({% link _docs/platforms/kubernetes/install/index.md %})&lt;/p&gt;
&lt;h2 id=&#34;deploying-cassandra-on-kubernetes&#34;&gt;Deploying Cassandra on Kubernetes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;You can find the latest files in the StorageOS example deployment repostiory
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/storageos/deploy.git storageos
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;StatefulSet defintion&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;apps/v1&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;StatefulSet&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;cassandra&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;selector&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;matchLabels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;cassandra&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;serviceName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;cassandra&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;replicas&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;...&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;...&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeMounts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;     &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;cassandra-data&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;       &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;mountPath&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;/var/lib/cassandra&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;...&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;volumeClaimTemplates&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;metadata&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;cassandra-data&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spec&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;accessModes&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ReadWriteOnce&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageClassName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;fast&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# StorageOS storageClass &lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;resources&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;     &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requests&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;       &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storage&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;5Gi&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This excerpt is from the StatefulSet definition. This file contains the
VolumeClaim template that will dynamically provision storage, using the
StorageOS storage class. Dynamic provisioning occurs as a volumeMount has
been declared with the same name as a VolumeClaimTemplate.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Move into the Cassandra examples folder and create the objects&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos
kubectl create -f ./k8s/examples/cassandra
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm Cassandra is up and running.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -w -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;cassandra
NAME          READY   STATUS    RESTARTS   AGE
cassandra-0   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          8m32s
cassandra-1   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          7m51s
cassandra-2   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          6m36s 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connect to the Cassandra client pod and connect to the Cassandra server through the
service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it cassandra-0 -- cqlsh cassandra-0.cassandra
Connected to K8Demo at cassandra-0.cassandra:9042.
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;cqlsh 5.0.1 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; Cassandra 3.11.3 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; CQL spec 3.4.4 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; Native protocol v4&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
Use HELP &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; help.
cqlsh&amp;gt; SELECT cluster_name, listen_address FROM system.local&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;

 cluster_name &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; listen_address
--------------+----------------
       K8Demo &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt;   100.96.7.124

&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt; rows&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cassandra</title>
      <link>/docs/usecases/cassandra/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/usecases/cassandra/</guid>
      <description>
        
        
        &lt;h1 id=&#34;imageimagesdocsexplorecassandralogopng-cassandra-with-storageos&#34;&gt;&lt;img src=&#34;/images/docs/explore/cassandralogo.png&#34; alt=&#34;image&#34;&gt; Cassandra with StorageOS&lt;/h1&gt;
&lt;p&gt;Cassandra is a popular distributed NoSQL open source database.&lt;/p&gt;
&lt;p&gt;Using StorageOS persistent volumes with Cassandra means that if a Cassandra pod
fails, the cluster is only in a degraded state for as long as it takes
Kubernetes to restart the pod. When the pod comes back up the pod data is
immediately available. Should Kubernetes schedule the Cassandra pod on a
new node, StorageOS allows for the data to be available to the pod,
irrespective of whether or not a StorageOS master is located on the same node.&lt;/p&gt;
&lt;p&gt;As Cassandra has features to allow it to handle replication careful
consideration of whether to allow StorageOS or Cassandra to handle replication
is required.&lt;/p&gt;
&lt;p&gt;Before you start, ensure you have StorageOS installed and ready on a Kubernetes
cluster. [See our guide on how to install StorageOS on Kubernetes for more
information]({% link _docs/platforms/kubernetes/install/index.md %}).&lt;/p&gt;
&lt;h2 id=&#34;deploying-cassandra-on-kubernetes&#34;&gt;Deploying Cassandra on Kubernetes&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You can find the latest files in the StorageOS use cases repository&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/storageos/use-cases.git storageos-usecases
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;StatefulSet defintion&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;apiVersion: apps/v1
kind: StatefulSet
metadata:
name: cassandra
spec:
selector:
matchLabels:
app: cassandra
serviceName: cassandra
replicas: 3
&amp;hellip;
spec:
&amp;hellip;
volumeMounts:
- name: cassandra-data
mountPath: /var/lib/cassandra
&amp;hellip;
volumeClaimTemplates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;metadata:
name: cassandra-data
spec:
accessModes: [&amp;ldquo;ReadWriteOnce&amp;rdquo;]
storageClassName: &amp;ldquo;fast&amp;rdquo; # StorageOS storageClass
resources:
requests:
storage: 5Gi
&lt;pre&gt;&lt;code&gt;
This excerpt is from the StatefulSet definition. This file contains the
VolumeClaim template that will dynamically provision storage, using the
StorageOS storage class. Dynamic provisioning occurs as a volumeMount has
been declared with the same name as a VolumeClaimTemplate.

&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Move into the Cassandra examples folder and create the objects&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; storageos-usecases
kubectl create -f ./cassandra
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm Cassandra is up and running.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl get pods -w -l &lt;span style=&#34;color:#000&#34;&gt;app&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;cassandra
NAME          READY   STATUS    RESTARTS   AGE
cassandra-0   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          8m32s
cassandra-1   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          7m51s
cassandra-2   1/1     Running   &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;          6m36s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Connect to the Cassandra client pod and connect to the Cassandra server through the
service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span style=&#34;color:#204a87&#34;&gt;exec&lt;/span&gt; -it cassandra-0 -- cqlsh cassandra-0.cassandra
Connected to K8Demo at cassandra-0.cassandra:9042.
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;cqlsh 5.0.1 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; Cassandra 3.11.3 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; CQL spec 3.4.4 &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; Native protocol v4&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
Use HELP &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; help.
cqlsh&amp;gt; SELECT cluster_name, listen_address FROM system.local&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt;

 cluster_name &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; listen_address
--------------+----------------
       K8Demo &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt;   100.96.7.124

&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt; rows&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cluster</title>
      <link>/docs/reference/cli/cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/cli/cluster/</guid>
      <description>
        
        
        &lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ storageos cluster

Usage:	storageos cluster COMMAND

Manage clusters

Aliases:
  cluster, c

Options:
      --help   Print usage

Commands:
  connectivity Display connectivity diagnostics &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; the cluster
  create       Creates a cluster initialization token.
  health       Displays the cluster&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;s health.
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  inspect      Display detailed information on one or more cluster
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  maintenance  Enable|disable maintenance mode for the cluster
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;  rm           Remove one or more clusters
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;Run &amp;#39;&lt;/span&gt;storageos cluster COMMAND --help&lt;span style=&#34;color:#a40000&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; more information on a command.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;storageos-cluster-connectivity&#34;&gt;&lt;code&gt;storageos cluster connectivity&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To check the connectivity of the cluster&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ storageos cluster connectivity
SOURCE                NAME                           ADDRESS           LATENCY     STATUS  MESSAGE
storageos-nodes2  storageos-nodes1.api       10.0.12.154:5705  1.085151ms  OK      
storageos-nodes2  storageos-nodes1.directfs  10.0.12.154:5703  1.09232ms   OK      
storageos-nodes2  storageos-nodes1.etcd      10.0.12.154:5707  1.142334ms  OK      
storageos-nodes2  storageos-nodes1.nats      10.0.12.154:5708  1.172353ms  OK      
storageos-nodes2  storageos-nodes1.serf      10.0.12.154:5711  1.11125ms   OK      
storageos-nodes2  storageos-nodes2.api       10.0.12.148:5705  1.204403ms  OK      
storageos-nodes2  storageos-nodes2.directfs  10.0.12.148:5703  1.134408ms  OK      
storageos-nodes2  storageos-nodes2.etcd      10.0.12.148:5707  1.115885ms  OK      
storageos-nodes2  storageos-nodes2.nats      10.0.12.148:5708  1.201178ms  OK      
storageos-nodes2  storageos-nodes2.serf      10.0.12.148:5711  1.111379ms  OK      
storageos-nodes2  storageos-nodes3.api       10.0.12.253:5705  1.143731ms  OK      
storageos-nodes2  storageos-nodes3.directfs  10.0.12.253:5703  1.149442ms  OK      
storageos-nodes2  storageos-nodes3.etcd      10.0.12.253:5707  1.083065ms  OK      
storageos-nodes2  storageos-nodes3.nats      10.0.12.253:5708  1.090467ms  OK      
storageos-nodes2  storageos-nodes3.serf      10.0.12.253:5711  1.158129ms  OK      
storageos-nodes3  storageos-nodes1.api       10.0.12.154:5705  1.145954ms  OK      
storageos-nodes3  storageos-nodes1.directfs  10.0.12.154:5703  1.114514ms  OK      
storageos-nodes3  storageos-nodes1.etcd      10.0.12.154:5707  1.214016ms  OK      
storageos-nodes3  storageos-nodes1.nats      10.0.12.154:5708  1.093753ms  OK      
storageos-nodes3  storageos-nodes1.serf      10.0.12.154:5711  1.076079ms  OK      
storageos-nodes3  storageos-nodes2.api       10.0.12.148:5705  1.206116ms  OK      
storageos-nodes3  storageos-nodes2.directfs  10.0.12.148:5703  1.077688ms  OK      
storageos-nodes3  storageos-nodes2.etcd      10.0.12.148:5707  1.079419ms  OK      
storageos-nodes3  storageos-nodes2.nats      10.0.12.148:5708  1.090791ms  OK      
storageos-nodes3  storageos-nodes2.serf      10.0.12.148:5711  1.15946ms   OK      
storageos-nodes3  storageos-nodes3.api       10.0.12.253:5705  1.098104ms  OK      
storageos-nodes3  storageos-nodes3.directfs  10.0.12.253:5703  1.154387ms  OK      
storageos-nodes3  storageos-nodes3.etcd      10.0.12.253:5707  1.147184ms  OK      
storageos-nodes3  storageos-nodes3.nats      10.0.12.253:5708  1.168365ms  OK      
storageos-nodes3  storageos-nodes3.serf      10.0.12.253:5711  1.10147ms   OK      
storageos-nodes1  storageos-nodes1.api       10.0.12.154:5705  1.141353ms  OK      
storageos-nodes1  storageos-nodes1.directfs  10.0.12.154:5703  1.10065ms   OK      
storageos-nodes1  storageos-nodes1.etcd      10.0.12.154:5707  1.143535ms  OK      
storageos-nodes1  storageos-nodes1.nats      10.0.12.154:5708  1.142812ms  OK      
storageos-nodes1  storageos-nodes1.serf      10.0.12.154:5711  1.125368ms  OK      
storageos-nodes1  storageos-nodes2.api       10.0.12.148:5705  1.126621ms  OK      
storageos-nodes1  storageos-nodes2.directfs  10.0.12.148:5703  1.114407ms  OK      
storageos-nodes1  storageos-nodes2.etcd      10.0.12.148:5707  1.192261ms  OK      
storageos-nodes1  storageos-nodes2.nats      10.0.12.148:5708  1.075251ms  OK      
storageos-nodes1  storageos-nodes2.serf      10.0.12.148:5711  1.191951ms  OK      
storageos-nodes1  storageos-nodes3.api       10.0.12.253:5705  1.080853ms  OK      
storageos-nodes1  storageos-nodes3.directfs  10.0.12.253:5703  1.084045ms  OK      
storageos-nodes1  storageos-nodes3.etcd      10.0.12.253:5707  1.117382ms  OK      
storageos-nodes1  storageos-nodes3.nats      10.0.12.253:5708  1.15015ms   OK      
storageos-nodes1  storageos-nodes3.serf      10.0.12.253:5711  1.075519ms  OK
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;storageos-cluster-create&#34;&gt;&lt;code&gt;storageos cluster create&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To create a cluster token for [cluster discovery]({%link
_docs/reference/clusterdiscovery.md %}):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ storageos cluster create
207f0026-3844-40e0-884b-729d79c124b8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;storageos-cluster-health&#34;&gt;&lt;code&gt;storageos cluster health&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To view the status of cluster nodes:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ storageos cluster health
NODE         CP_STATUS  DP_STATUS
storageos-1  Healthy    Healthy
storageos-2  Healthy    Healthy
storageos-3  Healthy    Healthy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To view the status in more detail there are additional format
options which can be given to the &lt;code&gt;--format&lt;/code&gt; flag:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cp&lt;/code&gt; shows the status of control plane components&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dp&lt;/code&gt; shows the status of data plane components&lt;/li&gt;
&lt;li&gt;&lt;code&gt;detailed&lt;/code&gt; shows the status of control plane and data plane components&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All the normal format options are available too. Run &lt;code&gt;storageos cluster health --format help&lt;/code&gt;
to see all the options for this command.&lt;/p&gt;
&lt;h3 id=&#34;storageos-cluster-inspect&#34;&gt;&lt;code&gt;storageos cluster inspect&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To inspect a cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ storageos cluster inspect 207f0026-3844-40e0-884b-729d79c124b8
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[&lt;/span&gt;
    &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;207f0026-3844-40e0-884b-729d79c124b8&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;size&amp;#34;&lt;/span&gt;: 3,
        &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;createdAt&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2017-07-14T13:17:29.226058526Z&amp;#34;&lt;/span&gt;,
        &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;updatedAt&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;2017-07-14T13:17:29.22605861Z&amp;#34;&lt;/span&gt;
    &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;storageos-cluster-maintenance-inspect&#34;&gt;&lt;code&gt;storageos cluster maintenance inspect&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To view the maintenance status of a cluster:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ storageos cluster maintenance inspect
[
    {
        &amp;quot;enabled&amp;quot;: false,
        &amp;quot;updatedBy&amp;quot;: &amp;quot;&amp;quot;,
        &amp;quot;updatedAt&amp;quot;: &amp;quot;0001-01-01T00:00:00Z&amp;quot;
    }
]

&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;storageos-cluster-rm&#34;&gt;&lt;code&gt;storageos cluster rm&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To remove a cluster:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;storageos cluster rm 207f0026-3844-40e0-884b-729d79c124b8
207f0026-3844-40e0-884b-729d79c124b8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Cluster discovery</title>
      <link>/docs/reference/clusterdiscovery/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/clusterdiscovery/</guid>
      <description>
        
        
        &lt;p&gt;On startup, you will need to specify whether a StorageOS node should bootstrap
a new cluster or join an existing cluster. In order for a bootstrapping node to
join or create a cluster, the node needs to know where to find the other nodes
in the cluster. The node is informed of other nodes in the cluster via the JOIN
environment variable.&lt;/p&gt;
&lt;h2 id=&#34;cluster-initialisation---using-storageos-operator&#34;&gt;Cluster Initialisation - Using StorageOS Operator&lt;/h2&gt;
&lt;p&gt;For standard installs, the StorageOS operator will automatically populate the
JOIN variable with appropriate values. For users with advanced requirements,
the operator allows specification of a custom JOIN variable.&lt;/p&gt;
&lt;h2 id=&#34;cluster-initialisation---advancedcustom-installations&#34;&gt;Cluster Initialisation - Advanced/Custom Installations&lt;/h2&gt;
&lt;p&gt;StorageOS offers a public discovery service, which is a convenient way to
pass clustering information to the StorageOS node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Create a cluster discovery token. This token is not used after initialization&lt;/span&gt;
$ storageos cluster create
017e4605-3c3a-434d-b4b1-dfe514a9cd0f

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Add the returned cluster ID token to the JOIN variable&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;JOIN&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;017e4605-3c3a-434d-b4b1-dfe514a9cd0f
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Alternatively, you can specify the IP addresses of nodes to join. If you
provide a list of node IPs any new node joining the cluster will attempt to
contact the node IPs specified. This means that if all the nodes in the JOIN
are unavailable that new nodes will be unable to join the cluster.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Specify a node to connect to in an existing cluster&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;JOIN&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;172.28.128.3

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Specify a list of nodes to attempt to connect to, in left-to-right order&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;JOIN&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;172.28.128.3,172.28.128.9,172.28.128.15

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Specify both the discovery service and IP addresses, tried left-to-right&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;JOIN&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;d53e9fae-7436-4185-82ea-c0446a52e2cd,172.28.128.3,172.28.128.9
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The &lt;code&gt;JOIN&lt;/code&gt; command line argument is always required, even in clusters with only
one node. A blank &lt;code&gt;JOIN&lt;/code&gt; variable will result in a non-functional cluster. This
is to prevent non-obvious split-brain scenarios in multi-node clusters, where
&lt;code&gt;JOIN&lt;/code&gt; was mistakenly omitted.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Create a one-node cluster; note that replicas are unavailable.&lt;/span&gt;
&lt;span style=&#34;color:#000&#34;&gt;JOIN&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$ADVERTISE_IP&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Clusters</title>
      <link>/docs/concepts/clusters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/clusters/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS clusters represent groups of nodes which run a common distributed
control plane, and aggregate their storage into one or more
&lt;a href=&#34;/docs/concepts/pools&#34;&gt;pools&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Typically, a StorageOS cluster maps one-to-one to a Kubernetes (or similar
orchestrator) cluster, and we expect our container to run on all worker
nodes within the cluster that will consume or present storage.&lt;/p&gt;
&lt;p&gt;Clusters use etcd to maintain state and manage distributed consensus between
nodes. We offer a choice between an internally managed etcd suitable for test
installations or the ability to interface with an external etcd, suitable for
production deployments. We recommend the use of external etcd when production
or production like workloads will be deployed on StorageOS.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Compression</title>
      <link>/docs/concepts/compression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/concepts/compression/</guid>
      <description>
        
        
        &lt;p&gt;StorageOS compression is handled on a per volume basis and is enabled by
default, as performance is generally increased when compression is enabled due
to fewer read/write operations taking place on the backend store (the volumes&amp;rsquo;
&lt;a href=&#34;/docs/concepts/volumes#blob-files&#34;&gt;blob files&lt;/a&gt;). Compression can be disabled
by setting the &lt;a href=&#34;/docs/reference/labels&#34;&gt;label&lt;/a&gt; &lt;code&gt;storageos.com/nocompress=true&lt;/code&gt;
on a volume.&lt;/p&gt;
&lt;p&gt;StorageOS utilises the &lt;a href=&#34;https://lz4.github.io/lz4/&#34;&gt;lz4 compression algorithm&lt;/a&gt;
when writing to the backend store and when compressing &lt;a href=&#34;/docs/concepts/replication&#34;&gt;replication
traffic&lt;/a&gt; before it is sent across the network.
Compression is granular per 4k block and data will remain
compressed/uncompressed once written to a volume. Therefore, compression can be
dynamically enabled and disabled by setting the &lt;code&gt;storageos.com/nocompress&lt;/code&gt;
label on a volume.&lt;/p&gt;
&lt;p&gt;StorageOS detects whether a block can be compressed or not by creating a
heuristic that predicts the size of a compressed block. If the heuristic
indicates that the compressed block is likely to be larger than the
original block then the uncompressed block is stored. Block size increases post
compression if the compression dictionary is added to a block that cannot be
compressed. By verifying whether blocks can be compressed, disk efficiency is
increased and CPU resources are not wasted on attempts to compress
uncompressible blocks. StorageOS&amp;rsquo; patented on disk format is used to tell
whether individual blocks are compressed without overhead. As such volume
compression can be dynamically enabled/disabled even while a volume is in use.&lt;/p&gt;
&lt;p&gt;When compression and &lt;a href=&#34;/docs/concepts/encryption&#34;&gt;encryption&lt;/a&gt; are both enabled
for a volume, blocks are compressed then encrypted.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Contributing to the docs</title>
      <link>/docs/reference/contributing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/reference/contributing/</guid>
      <description>
        
        
        &lt;p&gt;We are always looking to improve our documentation. If you like to help people
and can write, read on for the process for submitting your contributions. If your
guide is published, you&amp;rsquo;ll receive $250 per article by PayPal.&lt;/p&gt;
&lt;h2 id=&#34;content-guidelines&#34;&gt;Content guidelines&lt;/h2&gt;
&lt;p&gt;A guide contains step by step instructions for how to accomplish a specific
task using StorageOS. To be accepted, guides must be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Written in English.&lt;/li&gt;
&lt;li&gt;Relevant, accurate and complete.&lt;/li&gt;
&lt;li&gt;Technically correct and thoroughly tested.&lt;/li&gt;
&lt;li&gt;Follow the &lt;a href=&#34;https://github.com/storageos/storageos.github.io/blob/master/README.md&#34;&gt;writing style guide&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Guides should avoid:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Duplicating an existing guide or other sources, such as blogs or forum posts.&lt;/li&gt;
&lt;li&gt;Including irrelevant material.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;submission-and-review&#34;&gt;Submission and review&lt;/h2&gt;
&lt;p&gt;You should submit your guide as a pull request to
&lt;a href=&#34;https://github.com/storageos/storageos.github.io&#34;&gt;the GitHub repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Your submission will be left open for community review for two weeks. After
this, your submission will be reviewed internally for about another week.&lt;/p&gt;
&lt;p&gt;If accepted, your pull request will be approved and you will have 36 hours to
send your submission title and PayPal account information. Non-response will be
taken as a go-ahead to publish.&lt;/p&gt;
&lt;h2 id=&#34;legal&#34;&gt;Legal&lt;/h2&gt;
&lt;p&gt;COPYRIGHT OWNERSHIP. The StorageOS Guides &amp;amp; Tutorials repository is licensed
under the &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International&lt;/a&gt;
(CC BY-NC-SA 4.0) license.&lt;/p&gt;
&lt;p&gt;CREDIT. Nothing contained in this Agreement shall be deeded to require StorageOS
to use the Work, or any part thereof, in connection with StorageOS Guides &amp;amp;
Tutorials or otherwise. Credit for the Work shall read, “Contributed by &lt;em&gt;writer’s
name&lt;/em&gt;.”&lt;/p&gt;
&lt;p&gt;PAYMENT. Upon publication of a submission to the StorageOS Guides &amp;amp; Tutorials
Repository, the writer will be paid the sum of USD $250.00 as an electronic
payment.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
